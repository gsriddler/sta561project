{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required strings\n",
    "from LiarLiarPreProcessor import LiarLiarPreProcessor\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiarLiarPreProcessor Demo Script\n",
    "The following script demos the capabilities of the Liar Liar pre-processor that we used to encode the data. This is a wrapper of the PreProcessor class designed specifically for the LiarLiar Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the LiarLiarPreProcessor\n",
    "\n",
    "### Create an instance of the LiarLiarPreProcessor class and import the dataset from a file\n",
    "\n",
    "The preprocessor imports files based on the file name. The file must be located in the \"datasets\" folder. We automatically replace Null and NaN dataset entries with \"N/A\"\n",
    "\n",
    "When loading a dataset, the preProcessor automatically looks for a .tsv file named \"train.tsv\" in the \"datasets\" folder (must be in this folder) with the following column headers\n",
    "1. 'id': the ID of the statement ([ID].json).\n",
    "2. 'label': the label.\n",
    "3. 'statement': the statement.\n",
    "4. 'subjects': the subject(s).\n",
    "5. 'speaker': the speaker.\n",
    "6. 'speaker_job_title': the speaker's job title.\n",
    "7. 'state_info': the state info.\n",
    "8. 'party_affiliation': the party affiliation.\n",
    "\n",
    "Column 9-13: the total credit history count, including the current statement.\n",
    "\n",
    "9. 'count_1', pants on fire counts.\n",
    "10. 'count_2',false counts.\n",
    "11. 'count_3',barely true counts.\n",
    "12. 'count_4',half true counts.\n",
    "13. 'count_5',mostly on fire counts.\n",
    "\n",
    "14. 'context': the context (venue / location of the speech or statement).\n",
    "\n",
    "Asside from this, there are the following options:\n",
    "* replace_Null_Nan: This option automatically replaces an Null or NaN values with 'N/A' in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_liar_pre_processor = LiarLiarPreProcessor(verbose=False)\n",
    "\n",
    "#load the training data\n",
    "liar_liar_pre_processor.import_training_data(\n",
    "    file_name=\"train.tsv\",\n",
    "    deliminator='\\t',\n",
    "    custom_headers=None,\n",
    "    replace_Null_NaN=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoting which column in the dataset corresponds to the labels for each data sample\n",
    "\n",
    "We provide a custom encoding (optional) so that each possible label can be encoded using a unique number. For additional flexibility, the labels (or any set of data for that matter) can be encoded based on the following options:\n",
    "- Standard mapping: Labels are encoded either through the provided encoding_mapping or automatically using a unique integer for each label\n",
    "- normalized mapping: When it makes sense, labels can be normalized so as to range from 0 to 1\n",
    "- binarized mapping: Finally, labels can be binarized to be either 0 or 1. This generally only makes sense with only two labels or if data is specifically constructed to be binarized (ex: mostly true vs mostly false)\n",
    "\n",
    "\n",
    "By default, the labels for each data sample will come from the column titled: 'label' with the encoding as follows (although this can be changed):\n",
    "\n",
    "{'pants-fire':0,\n",
    "'false':1,\n",
    "'barely-true':2,\n",
    "'half-true':3,\n",
    "'mostly-true':4,\n",
    "'true':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the label column\n",
    "liar_liar_pre_processor.set_label_header(\n",
    "    label_header='label',\n",
    "    custom_label_encoding=False,\n",
    "    normalize=False,\n",
    "    binarize=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Obtaining a Dataset\n",
    "\n",
    "### Configuring a Dataset\n",
    "A data set is configured by supplying the preprocessor with a list of encoder configuration dictionaries\n",
    "\n",
    "### Types of encoders:\n",
    "\n",
    "There are three types of encoders:\n",
    "1. Standard encoder: this is the same encoder that is used to encode the labels, and it includes the same parameters (custom mapping, binarization, normalization)\n",
    "2. Bag-of-words: This encoder performs a bag-of-words encoding. It includes options to clean strings (clean up punctuation, ect), remove stop words (remove common words), and lematize (reduce words down to their simplest forms).\n",
    "3. Credit score encoder: This encoder computes a weighted average and uses the weighted average of the given columns as the encoding (ex: for a credit history score).\n",
    "\n",
    "### Applying Filters:\n",
    "\n",
    " The Standard Encoder and Bag-of-words encoders also support filtering for specific features. If desired, specify a list of exact features to only use those specific features when encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/STA561/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/david/Documents/sta561project/preprocess/Encoder.py:326: RuntimeWarning: invalid value encountered in divide\n",
      "  weighted_credit_counts = credit_counts / sums[:,None]\n"
     ]
    }
   ],
   "source": [
    "encoder_parameters = [\n",
    "    {\"encoder_name\": \"statement\",\n",
    "        \"encoder_type\":\"bag-of-words\",\n",
    "        \"feature_name\":\"statement\",\n",
    "        \"clean_strings\":True,\n",
    "        \"remove_stop_words\":True,\n",
    "        \"lematize\":True,\n",
    "        \"filtering\" : {\n",
    "            \"filtering_enabled\":False,\n",
    "            \"filtered_terms\": []\n",
    "        }\n",
    "    },\n",
    "    {\"encoder_name\": \"party affiliation\",\n",
    "        \"encoder_type\":\"encode\",\n",
    "        \"feature_name\":\"party_affiliation\",\n",
    "        \"encoding_mapping\":None,\n",
    "        \"normalize\":False,\n",
    "        \"Binarize\":False,\n",
    "        \"filtering\" : {\n",
    "            \"filtering_enabled\":True,\n",
    "            \"filtered_terms\": ['republican', 'democrat', 'none']\n",
    "        }\n",
    "    },\n",
    "    {\"encoder_name\": \"credit score\",\n",
    "        \"encoder_type\":\"credit history\",\n",
    "        \"feature_names\":['count_1','count_2','count_3','count_4','count_5'],\n",
    "        \"compute_credit_history\":True\n",
    "    }\n",
    "]\n",
    "\n",
    "#load the encoding configurations for the desired dataset\n",
    "\n",
    "liar_liar_pre_processor.configure_encodings(encoder_parameters=encoder_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X,X_headers = liar_liar_pre_processor.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/STA561/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/david/Documents/sta561project/preprocess/Encoder.py:326: RuntimeWarning: invalid value encountered in divide\n",
      "  weighted_credit_counts = credit_counts / sums[:,None]\n"
     ]
    }
   ],
   "source": [
    "#apply to the test set\n",
    "y_test,X_test = liar_liar_pre_processor.apply_encodings_to_new_data('test.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STA561",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff78712972ad1d9723777b77156440718eac6d60d034e137fcbf0563820b527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
